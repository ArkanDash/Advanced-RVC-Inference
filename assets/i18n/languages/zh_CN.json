{
    "## Embedder Information": "## Embedder Information",
    "## Embedder Models": "## Embedder Models",
    "## F0 Extractor": "## F0 Extractor",
    "## F0 Visualization": "## F0 Visualization",
    "## Voice Blender": "## Voice Blender",
    "## ğŸš€ Advanced Tools": "## ğŸš€ Advanced Tools",
    "## ğŸ§© Plugins": "## ğŸ§© Plugins",
    "### Plugin Configuration": "### Plugin Configuration",
    "Adjust the pitch of the audio.": "è°ƒæ•´éŸ³é¢‘çš„éŸ³é«˜ã€‚",
    "Adjust the volume of the Instrumentals.": "è°ƒæ•´å™¨ä¹çš„éŸ³é‡ã€‚",
    "Adjust the volume of the backing vocals.": "è°ƒæ•´ä¼´å”±çš„éŸ³é‡ã€‚",
    "Adjust the volume of the vocals.": "è°ƒæ•´äººå£°çš„éŸ³é‡ã€‚",
    "Advanced Settings": "é«˜çº§è®¾ç½®",
    "Advanced pitch extraction algorithm (KRVC Kernel optimized).": "Advanced pitch extraction algorithm (KRVC Kernel optimized).",
    "Advanced pitch extraction algorithm.": "Advanced pitch extraction algorithm.",
    "Algorithm for pitch extraction": "éŸ³é«˜æå–ç®—æ³•",
    "Analyze Model": "Analyze Model",
    "Applied reverb with room size": "Applied reverb with room size",
    "Apply Effects": "Apply Effects",
    "Apply a soft autotune to your inferences, recommended for singing conversions.": "å¯¹æ¨ç†åº”ç”¨æŸ”å’Œçš„è‡ªåŠ¨è°ƒéŸ³ï¼Œæ¨èç”¨äºæ­Œå”±è½¬æ¢ã€‚",
    "Apply audio effects during preprocessing": "åœ¨é¢„å¤„ç†æœŸé—´åº”ç”¨éŸ³é¢‘æ•ˆæœ",
    "Apply deeecho to the audio.": "å¯¹éŸ³é¢‘åº”ç”¨å»å›å£°ã€‚",
    "Apply denoise to the audio.": "å¯¹éŸ³é¢‘åº”ç”¨é™å™ªã€‚",
    "Apply reverb to the audio.": "å¯¹éŸ³é¢‘åº”ç”¨æ··å“ã€‚",
    "Audio Duration": "Audio Duration",
    "Audio Processing Quality": "Audio Processing Quality",
    "Audio Separation Settings": "éŸ³é¢‘åˆ†ç¦»è®¾ç½®",
    "Audio for F0 Extraction": "Audio for F0 Extraction",
    "Audio post-process Settings": "éŸ³é¢‘åå¤„ç†è®¾ç½®",
    "Audio sample rate": "éŸ³é¢‘é‡‡æ ·ç‡",
    "Audio with Effects": "Audio with Effects",
    "Auto Batch Size": "Auto Batch Size",
    "Auto Save Results": "Auto Save Results",
    "Automatically optimize batch size based on GPU": "Automatically optimize batch size based on GPU",
    "Autotune": "è‡ªåŠ¨è°ƒéŸ³",
    "Backing Vocals Index File": "Backing Vocals Index File",
    "Backing Vocals Model": "Backing Vocals Model",
    "Backing Vocals Volume": "ä¼´å”±éŸ³é‡",
    "Balanced (4-8 hours)": "å¹³è¡¡ï¼ˆ4-8å°æ—¶ï¼‰",
    "Batch Convert": "Batch Convert",
    "Batch Size": "æ‰¹å¤„ç†å¤§å°",
    "Batch Status": "Batch Status",
    "Batch processing completed for folder:": "Batch processing completed for folder:",
    "Bit Depth": "Bit Depth",
    "Blend Ratio (0.0 = First Model, 1.0 = Second Model)": "Blend Ratio (0.0 = First Model, 1.0 = Second Model)",
    "Blend Voices": "Blend Voices",
    "Blend multiple voices together to create unique voice combinations.": "Blend multiple voices together to create unique voice combinations.",
    "Blended Model": "Blended Model",
    "CPU Cores": "CPUæ ¸å¿ƒæ•°",
    "Cache Size (MB)": "Cache Size (MB)",
    "Change Instrumental Pitch": "Change Instrumental Pitch",
    "Change the pitch of the instrumental.": "Change the pitch of the instrumental.",
    "Choose a model to evaluate": "é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹",
    "Choose a model to train index for": "é€‰æ‹©è¦è®­ç»ƒç´¢å¼•çš„æ¨¡å‹",
    "Choose a pretrained model to start with": "é€‰æ‹©è¦å¼€å§‹çš„é¢„è®­ç»ƒæ¨¡å‹",
    "Choose training speed vs quality": "é€‰æ‹©è®­ç»ƒé€Ÿåº¦ä¸è´¨é‡",
    "Clear Outputs (Deletes all audios in assets/audios)": "æ¸…é™¤è¾“å‡ºï¼ˆåˆ é™¤assets/audiosä¸­çš„æ‰€æœ‰éŸ³é¢‘ï¼‰",
    "Comma separated GPU IDs": "é€—å·åˆ†éš”çš„GPU ID",
    "Comma separated GPU IDs (e.g., 0,1,2)": "Comma separated GPU IDs (e.g., 0,1,2)",
    "Complete training suite for RVC models": "RVCæ¨¡å‹å®Œæ•´è®­ç»ƒå¥—ä»¶",
    "Configuration Status": "Configuration Status",
    "Conversion Status": "Conversion Status",
    "Convert": "è½¬æ¢",
    "Convert Format": "Convert Format",
    "Convert Model": "Convert Model",
    "Converted Audio": "Converted Audio",
    "Custom Embedder Path (if 'custom' selected)": "Custom Embedder Path (if 'custom' selected)",
    "Custom Path": "Custom Path",
    "Dataset Folder Path": "æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„",
    "Dataset Path": "æ•°æ®é›†è·¯å¾„",
    "Dataset Preparation": "æ•°æ®é›†å‡†å¤‡",
    "Dataset Settings": "æ•°æ®é›†è®¾ç½®",
    "Dataset path and model name are required!": "æ•°æ®é›†è·¯å¾„å’Œæ¨¡å‹åç§°æ˜¯å¿…éœ€çš„ï¼",
    "Dataset path does not exist!": "æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼",
    "Dataset preprocessed successfully!": "æ•°æ®é›†é¢„å¤„ç†æˆåŠŸï¼",
    "Dataset preprocessing completed": "æ•°æ®é›†é¢„å¤„ç†å®Œæˆ",
    "Deeecho": "å»å›å£°",
    "Deeecho Model": "å»å›å£°æ¨¡å‹",
    "Default Output Format": "Default Output Format",
    "Delete Audios": "åˆ é™¤éŸ³é¢‘",
    "Delete Selected": "Delete Selected",
    "Delete the audios after the conversion.": "è½¬æ¢ååˆ é™¤éŸ³é¢‘ã€‚",
    "Denoise": "é™å™ª",
    "Denoise Model": "é™å™ªæ¨¡å‹",
    "Dereverb Model": "å»æ··å“æ¨¡å‹",
    "Device": "è®¾å¤‡",
    "Device Settings": "è®¾å¤‡è®¾ç½®",
    "Disable Selected": "Disable Selected",
    "Download": "ä¸‹è½½",
    "Download Selected": "Download Selected",
    "Embedder Model": "åµŒå…¥æ¨¡å‹",
    "Embeddings extracted successfully": "Embeddings extracted successfully",
    "Enable GPU Optimization": "Enable GPU Optimization",
    "Enable Selected": "Enable Selected",
    "Enable Tensor Cores": "Enable Tensor Cores",
    "Enable automatic GPU optimization for T4/A100": "Enable automatic GPU optimization for T4/A100",
    "Enable pitch guidance for voice conversion": "ä¸ºè¯­éŸ³è½¬æ¢å¯ç”¨éŸ³é«˜æŒ‡å¯¼",
    "Enhance Audio": "Enhance Audio",
    "Enhanced Output": "Enhanced Output",
    "Enhancement Strength": "Enhancement Strength",
    "Enhancement Type": "Enhancement Type",
    "Enter model name...": "Enter model name...",
    "Enter name for your model": "Enter name for your model",
    "Enter name for your new model": "è¾“å…¥æ–°æ¨¡å‹çš„åç§°",
    "Enter output path": "è¾“å…¥è¾“å‡ºè·¯å¾„",
    "Enter path to custom embedder model": "Enter path to custom embedder model",
    "Enter path to your audio dataset folder": "è¾“å…¥éŸ³é¢‘æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„",
    "Enter text to convert to speech here...": "Enter text to convert to speech here...",
    "Enter your model name": "Enter your model name",
    "Epoch": "è½®",
    "Error": "Error",
    "Error during F0 extraction": "Error during F0 extraction",
    "Error during preprocessing": "é¢„å¤„ç†æœŸé—´å‡ºé”™",
    "Error during training": "è®­ç»ƒæœŸé—´å‡ºé”™",
    "Error extracting embeddings": "Error extracting embeddings",
    "Error loading model info": "Error loading model info",
    "Error:": "é”™è¯¯ï¼š",
    "Error: Invalid dataset path": "é”™è¯¯ï¼šæ— æ•ˆçš„æ•°æ®é›†è·¯å¾„",
    "Error: Please enter a model name": "é”™è¯¯ï¼šè¯·è¾“å…¥æ¨¡å‹åç§°",
    "Evaluate Model": "è¯„ä¼°æ¨¡å‹",
    "Evaluation Results": "è¯„ä¼°ç»“æœ",
    "Evaluation Settings": "è¯„ä¼°è®¾ç½®",
    "Evaluation completed!": "è¯„ä¼°å®Œæˆï¼",
    "Evaluation failed:": "è¯„ä¼°å¤±è´¥ï¼š",
    "Export Audio": "å¯¼å‡ºéŸ³é¢‘",
    "Export Format": "å¯¼å‡ºæ ¼å¼",
    "Extract F0": "æå–F0",
    "Extract Features": "æå–ç‰¹å¾",
    "Extract Pitch": "æå–éŸ³é«˜",
    "Extract Pitch Info": "æå–éŸ³é«˜ä¿¡æ¯",
    "Extract pitch contours from audio using various methods.": "Extract pitch contours from audio using various methods.",
    "Extract pitch information": "æå–éŸ³é«˜ä¿¡æ¯",
    "Extract speaker features": "æå–è¯´è¯äººç‰¹å¾",
    "Extracted Embeddings Shape": "Extracted Embeddings Shape",
    "Extracted features": "æå–çš„ç‰¹å¾",
    "Extraction Info": "Extraction Info",
    "Extraction Layer": "Extraction Layer",
    "Extraction Layer (-1 = final)": "Extraction Layer (-1 = final)",
    "Extraction Progress": "æå–è¿›åº¦",
    "Extraction Settings": "æå–è®¾ç½®",
    "Extraction Status": "Extraction Status",
    "F0 (Hz)": "F0 (Hz)",
    "F0 Curve": "F0 Curve",
    "F0 Extraction Method": "F0 Extraction Method",
    "F0 extracted successfully!": "F0æå–æˆåŠŸï¼",
    "F0 extracted using ": "F0 extracted using ",
    "F0 extraction completed:": "F0 extraction completed:",
    "F0 extraction failed:": "F0æå–å¤±è´¥ï¼š",
    "Fast (2-4 hours)": "å¿«é€Ÿï¼ˆ2-4å°æ—¶ï¼‰",
    "Feature Extraction": "ç‰¹å¾æå–",
    "Feature extraction completed:": "ç‰¹å¾æå–å®Œæˆï¼š",
    "Feature extraction failed:": "ç‰¹å¾æå–å¤±è´¥ï¼š",
    "Features extracted successfully!": "ç‰¹å¾æå–æˆåŠŸï¼",
    "Filter Radius": "æ»¤æ³¢åŠå¾„",
    "First Model": "First Model",
    "Found audio files": "æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶",
    "Fuse Models": "Fuse Models",
    "GPU IDs": "GPU ID",
    "GPU IDs (comma separated)": "GPU IDï¼ˆé€—å·åˆ†éš”ï¼‰",
    "GPU Optimization": "GPU Optimization",
    "Generate Speech": "Generate Speech",
    "Generated Speech": "Generated Speech",
    "Hidden Dim": "Hidden Dim",
    "High Quality (8-16 hours)": "é«˜è´¨é‡ï¼ˆ8-16å°æ—¶ï¼‰",
    "Hop Length": "è·³è·ƒé•¿åº¦",
    "Hop length for pitch extraction.": "éŸ³é«˜æå–çš„è·³è·ƒé•¿åº¦ã€‚",
    "If the number is greater than or equal to three, employing median filtering on the collected tone results has the potential to decrease respiration.": "å¦‚æœæ•°å­—å¤§äºæˆ–ç­‰äºä¸‰ï¼Œå¯¹æ”¶é›†åˆ°çš„éŸ³è°ƒç»“æœé‡‡ç”¨ä¸­å€¼æ»¤æ³¢æœ‰å¯èƒ½å‡å°‘å‘¼å¸å£°ã€‚",
    "Index File": "ç´¢å¼•æ–‡ä»¶",
    "Index File (Optional)": "Index File (Optional)",
    "Index Rate": "ç´¢å¼•ç‡",
    "Index Settings": "ç´¢å¼•è®¾ç½®",
    "Index Training": "ç´¢å¼•è®­ç»ƒ",
    "Index Training Progress": "ç´¢å¼•è®­ç»ƒè¿›åº¦",
    "Index rate for feature matching": "ç‰¹å¾åŒ¹é…çš„ç´¢å¼•ç‡",
    "Index trained successfully!": "ç´¢å¼•è®­ç»ƒæˆåŠŸï¼",
    "Index training completed!": "ç´¢å¼•è®­ç»ƒå®Œæˆï¼",
    "Index training failed:": "ç´¢å¼•è®­ç»ƒå¤±è´¥ï¼š",
    "Infer Backing Vocals": "Infer Backing Vocals",
    "Infer the bakcing vocals too.": "Infer the bakcing vocals too.",
    "Influence exerted by the index file; a higher value corresponds to greater influence.": "Influence exerted by the index file; a higher value corresponds to greater influence.",
    "Influence exerted by the index file; a higher value corresponds to greater influence. However, opting for lower values can help mitigate artifacts present in the audio.": "ç´¢å¼•æ–‡ä»¶äº§ç”Ÿçš„å½±å“ï¼›æ•°å€¼è¶Šé«˜ï¼Œå½±å“è¶Šå¤§ã€‚ç„¶è€Œï¼Œé€‰æ‹©è¾ƒä½çš„æ•°å€¼å¯ä»¥å¸®åŠ©å‡è½»éŸ³é¢‘ä¸­å­˜åœ¨çš„ä¼ªå½±ã€‚",
    "Input Audio": "Input Audio",
    "Input Folder Path": "Input Folder Path",
    "Input Microphone": "Input Microphone",
    "Input Model": "Input Model",
    "Install Plugin": "Install Plugin",
    "Instrumentals Volume": "å™¨ä¹éŸ³é‡",
    "Invalid preset selected!": "é€‰æ‹©äº†æ— æ•ˆçš„é¢„è®¾ï¼",
    "Karaoke Model": "å¡æ‹‰OKæ¨¡å‹",
    "Language": "Language",
    "Layers": "Layers",
    "Learning Rate": "å­¦ä¹ ç‡",
    "Load Model & Test Embedding": "Load Model & Test Embedding",
    "Loss": "æŸå¤±",
    "Manage and configure plugins for extended functionality.": "Manage and configure plugins for extended functionality.",
    "Mapped to": "Mapped to",
    "Max F0": "Max F0",
    "Max Frames": "æœ€å¤§å¸§æ•°",
    "Maximum number of frames to use": "ä½¿ç”¨çš„æœ€å¤§å¸§æ•°",
    "Memory Cleanup": "Memory Cleanup",
    "Memory Efficient Training": "Memory Efficient Training",
    "Min F0": "Min F0",
    "Mixed Precision": "Mixed Precision",
    "Mixed precision training mode": "Mixed precision training mode",
    "Model Analysis": "Model Analysis",
    "Model Evaluation": "æ¨¡å‹è¯„ä¼°",
    "Model File": "Model File",
    "Model Information": "Model Information",
    "Model Name": "æ¨¡å‹åç§°",
    "Model Training": "æ¨¡å‹è®­ç»ƒ",
    "Model URL": "æ¨¡å‹é“¾æ¥",
    "Model Version": "æ¨¡å‹ç‰ˆæœ¬",
    "Model conversion to": "Model conversion to",
    "Model info not available for": "Model info not available for",
    "Model loaded successfully": "Model loaded successfully",
    "Model name and dataset path are required!": "Model name and dataset path are required!",
    "Model name and test audio path are required!": "Model name and test audio path are required!",
    "Model name is required!": "æ¨¡å‹åç§°æ˜¯å¿…éœ€çš„ï¼",
    "Model to Evaluate": "è¦è¯„ä¼°çš„æ¨¡å‹",
    "Model used for learning speaker embedding (KRVC Kernel optimized).": "Model used for learning speaker embedding (KRVC Kernel optimized).",
    "Model used for learning speaker embedding.": "ç”¨äºå­¦ä¹ è¯´è¯äººåµŒå…¥çš„æ¨¡å‹ã€‚",
    "Music URL": "éŸ³ä¹é“¾æ¥",
    "Name for your new model": "æ–°æ¨¡å‹çš„åç§°",
    "Normalize Audio": "Normalize Audio",
    "Number of CPU cores to use": "ä½¿ç”¨çš„CPUæ ¸å¿ƒæ•°",
    "Output": "è¾“å‡º",
    "Output Folder Path": "Output Folder Path",
    "Output Format": "Output Format",
    "Output Information": "è¾“å‡ºä¿¡æ¯",
    "Output Path": "è¾“å‡ºè·¯å¾„",
    "Output Sample Rate": "Output Sample Rate",
    "Path to save evaluation results": "ä¿å­˜è¯„ä¼°ç»“æœçš„è·¯å¾„",
    "Path to your training dataset": "è®­ç»ƒæ•°æ®é›†è·¯å¾„",
    "Pitch": "éŸ³é«˜",
    "Pitch Change": "Pitch Change",
    "Pitch Change (semitones)": "Pitch Change (semitones)",
    "Pitch Extraction Algorithm": "éŸ³é«˜æå–ç®—æ³•",
    "Pitch Extraction Method": "éŸ³é«˜æå–æ–¹æ³•",
    "Pitch Extractor": "éŸ³é«˜æå–å™¨",
    "Pitch extract Algorith.": "éŸ³é«˜æå–ç®—æ³•ã€‚",
    "Pitch extraction completed:": "éŸ³é«˜æå–å®Œæˆï¼š",
    "Please enter some text to synthesize.": "Please enter some text to synthesize.",
    "Please provide a model file to convert.": "Please provide a model file to convert.",
    "Please provide a valid dataset folder path": "è¯·æä¾›æœ‰æ•ˆçš„æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„",
    "Please provide an audio file": "Please provide an audio file",
    "Please provide an audio file for F0 extraction.": "Please provide an audio file for F0 extraction.",
    "Please provide an audio file for effects processing.": "Please provide an audio file for effects processing.",
    "Please provide test audio": "Please provide test audio",
    "Please specify a custom embedder path": "Please specify a custom embedder path",
    "Please specify both input and output folders.": "Please specify both input and output folders.",
    "Please upload two models to blend.": "Please upload two models to blend.",
    "Plugin Configuration": "Plugin Configuration",
    "Plugin Name": "Plugin Name",
    "Preload Models": "Preload Models",
    "Preprocess Dataset": "é¢„å¤„ç†æ•°æ®é›†",
    "Preprocessing Output": "é¢„å¤„ç†è¾“å‡º",
    "Preprocessing Progress": "é¢„å¤„ç†è¿›åº¦",
    "Preprocessing completed successfully!": "é¢„å¤„ç†å®ŒæˆæˆåŠŸï¼",
    "Preprocessing dataset at": "é¢„å¤„ç†æ•°æ®ä½äº",
    "Preprocessing failed:": "é¢„å¤„ç†å¤±è´¥ï¼š",
    "Pretrained Model": "é¢„è®­ç»ƒæ¨¡å‹",
    "Process Audio Effects": "å¤„ç†éŸ³é¢‘æ•ˆæœ",
    "Process Effects": "å¤„ç†æ•ˆæœ",
    "Processing Threads": "Processing Threads",
    "Processing time": "Processing time",
    "Protect Voiceless Consonants": "ä¿æŠ¤æ¸…è¾…éŸ³",
    "Provide test audio to extract embeddings": "Provide test audio to extract embeddings",
    "Quick Train": "å¿«é€Ÿè®­ç»ƒ",
    "Quick Training with Presets": "ä½¿ç”¨é¢„è®¾å¿«é€Ÿè®­ç»ƒ",
    "Quick training completed!": "Quick training completed!",
    "Quick training failed:": "Quick training failed:",
    "Quick training started. This may take several hours.": "å¿«é€Ÿè®­ç»ƒå·²å¼€å§‹ã€‚è¿™å¯èƒ½éœ€è¦å‡ å°æ—¶ã€‚",
    "RVC Settings": "RVCè®¾ç½®",
    "RVC Settings for Backing vocals": "RVC Settings for Backing vocals",
    "RVC Training Center": "RVCè®­ç»ƒä¸­å¿ƒ",
    "Refresh": "åˆ·æ–°",
    "Refresh Models": "Refresh Models",
    "Remove Silence": "Remove Silence",
    "Reset to Defaults": "Reset to Defaults",
    "Results": "ç»“æœ",
    "Reverb": "æ··å“",
    "Reverb Damping": "æ··å“é˜»å°¼",
    "Reverb Dry Gain": "æ··å“å¹²å¢ç›Š",
    "Reverb Room Size": "æ··å“æˆ¿é—´å¤§å°",
    "Reverb Wet Gain": "æ··å“æ¹¿å¢ç›Š",
    "Reverb Width": "æ··å“å®½åº¦",
    "Safeguard distinct consonants and breathing sounds to prevent electro-acoustic tearing and other artifacts. Pulling the parameter to its maximum value of 0.5 offers comprehensive protection. However, reducing this value might decrease the extent of protection while potentially mitigating the indexing effect.": "ä¿æŠ¤æ¸…æ™°çš„è¾…éŸ³å’Œå‘¼å¸å£°ï¼Œä»¥é˜²æ­¢ç”µå£°æ’•è£‚å’Œå…¶ä»–ä¼ªå½±ã€‚å°†å‚æ•°æ‹‰åˆ°æœ€å¤§å€¼0.5æä¾›å…¨é¢ä¿æŠ¤ã€‚ç„¶è€Œï¼Œå‡å°‘è¿™ä¸ªå€¼å¯èƒ½ä¼šé™ä½ä¿æŠ¤ç¨‹åº¦ï¼ŒåŒæ—¶å¯èƒ½å‡è½»ç´¢å¼•æ•ˆåº”ã€‚",
    "Safeguard distinct consonants and breathing sounds.": "Safeguard distinct consonants and breathing sounds.",
    "Sample Rate": "é‡‡æ ·ç‡",
    "Save Configuration": "Save Configuration",
    "Save Every Epoch": "æ¯è½®ä¿å­˜",
    "Save Every N Epochs": "æ¯Nè½®ä¿å­˜",
    "Save Only Latest Checkpoint": "ä»…ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹",
    "Save every": "æ¯",
    "Save model every N epochs": "æ¯Nè½®ä¿å­˜æ¨¡å‹",
    "Save only the latest checkpoint to save space": "ä»…ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹ä»¥èŠ‚çœç©ºé—´",
    "Search Feature Ratio": "æœç´¢ç‰¹å¾æ¯”ç‡",
    "Search Models": "Search Models",
    "Search Online": "Search Online",
    "Search for models online...": "Search for models online...",
    "Second Model": "Second Model",
    "Select Audio": "é€‰æ‹©éŸ³é¢‘",
    "Select Model": "é€‰æ‹©æ¨¡å‹",
    "Select and configure embedder models for voice conversion.": "Select and configure embedder models for voice conversion.",
    "Select model version": "é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬",
    "Select the audio to convert.": "é€‰æ‹©è¦è½¬æ¢çš„éŸ³é¢‘ã€‚",
    "Select the backing vocals index file to use for the conversion.": "Select the backing vocals index file to use for the conversion.",
    "Select the backing vocals model to use for the conversion.": "Select the backing vocals model to use for the conversion.",
    "Select the deeecho model to use for the separation.": "é€‰æ‹©ç”¨äºåˆ†ç¦»çš„å»å›å£°æ¨¡å‹ã€‚",
    "Select the denoise model to use for the separation.": "é€‰æ‹©ç”¨äºåˆ†ç¦»çš„é™å™ªæ¨¡å‹ã€‚",
    "Select the dereverb model to use for the separation.": "é€‰æ‹©ç”¨äºåˆ†ç¦»çš„å»æ··å“æ¨¡å‹ã€‚",
    "Select the device to use for the conversion. 0 to âˆ separated by - and for CPU leave only an -": "é€‰æ‹©ç”¨äºè½¬æ¢çš„è®¾å¤‡ã€‚0åˆ°âˆç”¨-åˆ†éš”ï¼ŒCPUåªéœ€ç•™ä¸€ä¸ª-",
    "Select the format to export the audio.": "é€‰æ‹©å¯¼å‡ºéŸ³é¢‘çš„æ ¼å¼ã€‚",
    "Select the index file for real-time conversion.": "Select the index file for real-time conversion.",
    "Select the index file to use for the conversion.": "é€‰æ‹©ç”¨äºè½¬æ¢çš„ç´¢å¼•æ–‡ä»¶ã€‚",
    "Select the karaoke model to use for the separation.": "é€‰æ‹©ç”¨äºåˆ†ç¦»çš„å¡æ‹‰OKæ¨¡å‹ã€‚",
    "Select the theme you want to use. (Requires restarting the App)": "Select the theme you want to use. (Requires restarting the App)",
    "Select the vocals model to use for the separation.": "é€‰æ‹©ç”¨äºåˆ†ç¦»çš„äººå£°æ¨¡å‹ã€‚",
    "Select the voice model for real-time conversion.": "Select the voice model for real-time conversion.",
    "Select the voice model to use for the conversion.": "é€‰æ‹©ç”¨äºè½¬æ¢çš„è¯­éŸ³æ¨¡å‹ã€‚",
    "Selected Embedder": "Selected Embedder",
    "Set the batch size for the separation.": "è®¾ç½®åˆ†ç¦»çš„æ‰¹å¤„ç†å¤§å°ã€‚",
    "Set the damping of the reverb.": "è®¾ç½®æ··å“çš„é˜»å°¼ã€‚",
    "Set the dry gain of the reverb.": "è®¾ç½®æ··å“çš„å¹²å¢ç›Šã€‚",
    "Set the room size of the reverb.": "è®¾ç½®æ··å“çš„æˆ¿é—´å¤§å°ã€‚",
    "Set the wet gain of the reverb.": "è®¾ç½®æ··å“çš„æ¹¿å¢ç›Šã€‚",
    "Set the width of the reverb.": "è®¾ç½®æ··å“çš„å®½åº¦ã€‚",
    "Settings": "Settings",
    "Single": "Single",
    "Size": "Size",
    "Speed": "Speed",
    "Split Audio": "åˆ†å‰²éŸ³é¢‘",
    "Split the audio into chunks for inference to obtain better results in some cases.": "å°†éŸ³é¢‘åˆ†å‰²æˆå—è¿›è¡Œæ¨ç†ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯è·å¾—æ›´å¥½ç»“æœã€‚",
    "Start Extraction": "å¼€å§‹æå–",
    "Start Quick Training": "å¼€å§‹å¿«é€Ÿè®­ç»ƒ",
    "Start Real-Time Conversion": "Start Real-Time Conversion",
    "Start Training": "å¼€å§‹è®­ç»ƒ",
    "Starting training for model": "å¼€å§‹è®­ç»ƒæ¨¡å‹",
    "Status": "çŠ¶æ€",
    "Step 1: Preprocess Dataset": "æ­¥éª¤1ï¼šé¢„å¤„ç†æ•°æ®é›†",
    "Step 2: Extract F0": "æ­¥éª¤2ï¼šæå–F0",
    "Step 3: Extract Features": "æ­¥éª¤3ï¼šæå–ç‰¹å¾",
    "Step 4: Start Training": "æ­¥éª¤4ï¼šå¼€å§‹è®­ç»ƒ",
    "Step 5: Train Index": "æ­¥éª¤5ï¼šè®­ç»ƒç´¢å¼•",
    "Stop Conversion": "Stop Conversion",
    "Substitute or blend with the volume envelope of the input.": "Substitute or blend with the volume envelope of the input.",
    "Substitute or blend with the volume envelope of the output. The closer the ratio is to 1, the more the output envelope is employed.": "æ›¿æ¢æˆ–æ··åˆè¾“å‡ºçš„éŸ³é‡åŒ…ç»œã€‚æ¯”ç‡è¶Šæ¥è¿‘1ï¼Œä½¿ç”¨è¾“å‡ºåŒ…ç»œè¶Šå¤šã€‚",
    "Successfully extracted embeddings": "Successfully extracted embeddings",
    "Supported Modes": "Supported Modes",
    "TTS feature is implemented. In a complete version, this would generate speech from text using advanced TTS models.": "TTS feature is implemented. In a complete version, this would generate speech from text using advanced TTS models.",
    "Temp Folder": "Temp Folder",
    "Test Audio": "æµ‹è¯•éŸ³é¢‘",
    "Test Audio (optional)": "Test Audio (optional)",
    "Test Embedding Only": "Test Embedding Only",
    "Text to Synthesize": "Text to Synthesize",
    "The output information will be displayed here.": "è¾“å‡ºä¿¡æ¯å°†åœ¨è¿™é‡Œæ˜¾ç¤ºã€‚",
    "The path where the output audio will be saved, by default in audio_files/rvc/output.wav": "è¾“å‡ºéŸ³é¢‘ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºaudio_files/rvc/output.wav",
    "Theme": "Theme",
    "Time": "æ—¶é—´",
    "Time (s)": "Time (s)",
    "Total Epochs": "æ€»è½®æ•°",
    "Total Frames": "Total Frames",
    "Total epochs": "æ€»è½®æ•°",
    "Total number of training epochs": "è®­ç»ƒæ€»è½®æ•°",
    "Train Index": "è®­ç»ƒç´¢å¼•",
    "Training Preset": "è®­ç»ƒé¢„è®¾",
    "Training Progress": "è®­ç»ƒè¿›åº¦",
    "Training Settings": "è®­ç»ƒè®¾ç½®",
    "Training batch size": "è®­ç»ƒæ‰¹å¤„ç†å¤§å°",
    "Training checkpoint saved": "è®­ç»ƒæ£€æŸ¥ç‚¹å·²ä¿å­˜",
    "Training completed successfully!": "è®­ç»ƒå®ŒæˆæˆåŠŸï¼",
    "Training failed:": "è®­ç»ƒå¤±è´¥ï¼š",
    "Training learning rate": "è®­ç»ƒå­¦ä¹ ç‡",
    "Training started for model": "æ¨¡å‹è®­ç»ƒå·²å¼€å§‹",
    "Training started in background. Check logs for progress.": "è®­ç»ƒå·²åœ¨åå°å¼€å§‹ã€‚æ£€æŸ¥æ—¥å¿—ä»¥äº†è§£è¿›åº¦ã€‚",
    "Type": "Type",
    "Unload Voice": "å¸è½½è¯­éŸ³",
    "Upload Audio": "ä¸Šä¼ éŸ³é¢‘",
    "Upload test audio for evaluation": "ä¸Šä¼ æµ‹è¯•éŸ³é¢‘è¿›è¡Œè¯„ä¼°",
    "Use Pitch Guidance": "ä½¿ç”¨éŸ³é«˜æŒ‡å¯¼",
    "Use TTA": "ä½¿ç”¨TTA",
    "Use Test Time Augmentation.": "ä½¿ç”¨æµ‹è¯•æ—¶é—´å¢å¼ºã€‚",
    "Use gradient accumulation for memory efficiency": "Use gradient accumulation for memory efficiency",
    "Use tensor cores for A100 GPUs": "Use tensor cores for A100 GPUs",
    "Version": "Version",
    "Vocals Model": "äººå£°æ¨¡å‹",
    "Vocals Volume": "äººå£°éŸ³é‡",
    "Voice Model": "è¯­éŸ³æ¨¡å‹",
    "Voice Selection": "Voice Selection",
    "Voice blending feature is implemented. In a complete version, this would blend two voice models based on the specified ratio.": "Voice blending feature is implemented. In a complete version, this would blend two voice models based on the specified ratio.",
    "Volume Envelope": "éŸ³é‡åŒ…ç»œ",
    "Your training dataset location": "Your training dataset location",
    "completed": "completed",
    "damping": "damping",
    "e.g., 0,1,2": "ä¾‹å¦‚ï¼š0,1,2",
    "e.g., path/to/your/dataset": "e.g., path/to/your/dataset",
    "epochs": "è½®ä¿å­˜",
    "semitones": "semitones",
    "âš¡ Quick Train": "âš¡ Quick Train",
    "âœ… Model Evaluation": "âœ… Model Evaluation",
    "ğŸ“ Model Training": "ğŸ“ Model Training",
    "ğŸ“ˆ Index Training": "ğŸ“ˆ Index Training",
    "ğŸ“Š Dataset Preparation": "ğŸ“Š Dataset Preparation",
    "ğŸ”§ Feature Extraction": "ğŸ”§ Feature Extraction",
    "ğŸš€ GPU Optimization (T4/A100)": "ğŸš€ GPU Optimization (T4/A100)"
}
