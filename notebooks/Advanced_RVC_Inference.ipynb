{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ **Advanced RVC Inference Pro**\n",
    "\n",
    "**The Ultimate Voice Conversion Notebook**\n",
    "\n",
    "This notebook is optimized for speed, stability, and ease of use. \n",
    "\n",
    "### ‚ú® Features:\n",
    "- ‚ö° **Ultra-Fast Setup**: Powered by `uv` and `aria2` for maximum speed.\n",
    "- üì• **Model Downloader**: Built-in tool to download voice models from links.\n",
    "- üíæ **Drive Integration**: Seamlessly load/save models to Google Drive.\n",
    "- üåê **Robust Tunneling**: Auto-reconnecting Gradio and Ngrok integration.\n",
    "- üõ†Ô∏è **Auto-Fix**: Automatically installs missing system dependencies (FFmpeg).\n",
    "\n",
    "**Repository:** [ArkanDash/Advanced-RVC-Inference](https://github.com/ArkanDash/Advanced-RVC-Inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title ## üõ†Ô∏è 1. Initialize Environment\n",
    "# @markdown Installs system dependencies and sets up the `uv` package manager.\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def run_cmd(cmd, msg=None):\n",
    "    if msg:\n",
    "        print(f\"üëâ {msg}...\")\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"üöÄ Initializing Advanced RVC Environment...\")\n",
    "\n",
    "# 1. Install System Dependencies (FFmpeg is critical for RVC)\n",
    "print(\"üì¶ Installing system dependencies (FFmpeg, Aria2)...\")\n",
    "run_cmd(\"apt-get update -qq && apt-get install -y -qq ffmpeg aria2\")\n",
    "\n",
    "# 2. Install uv for fast python management\n",
    "print(\"‚ö° Installing uv package manager...\")\n",
    "run_cmd(\"pip install uv\")\n",
    "\n",
    "# 3. Clone Repository\n",
    "REPO_URL = \"https://github.com/ArkanDash/Advanced-RVC-Inference.git\"\n",
    "PROJECT_DIR = Path(\"/content/Advanced-RVC-Inference\")\n",
    "\n",
    "if not PROJECT_DIR.exists():\n",
    "    print(f\"üì• Cloning repository from {REPO_URL}...\")\n",
    "    run_cmd(f\"git clone {REPO_URL} {PROJECT_DIR}\")\n",
    "else:\n",
    "    print(\"üîÑ Repository exists. Updating...\")\n",
    "    run_cmd(f\"cd {PROJECT_DIR} && git pull\")\n",
    "\n",
    "# 4. Install Python Dependencies via uv\n",
    "print(\"üêç Installing Python libraries (this may take a moment)...\")\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Install requirements with uv system-wide to work with Colab\n",
    "requirements_cmd = (\n",
    "    \"uv pip install --system \"\n",
    "    \"torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 \"\n",
    "    \"--extra-index-url https://download.pytorch.org/whl/cu118 \"\n",
    "    \"-r requirements.txt\"\n",
    ")\n",
    "run_cmd(requirements_cmd)\n",
    "\n",
    "# Install pyngrok for better tunneling\n",
    "run_cmd(\"uv pip install --system pyngrok\")\n",
    "\n",
    "clear_output()\n",
    "print(f\"‚úÖ Setup completed in {time.time() - start_time:.2f} seconds!\")\n",
    "print(f\"üìÇ Working Directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title ## üíæ 2. Mount Drive & Sync Models\n",
    "# @markdown Syncs your models/weights folder with Google Drive so you don't lose them.\n",
    "\n",
    "mount_drive = True #@param {type:\"boolean\"}\n",
    "drive_folder_name = \"RVC_Backups\" #@param {type:\"string\"}\n",
    "\n",
    "import shutil\n",
    "\n",
    "if mount_drive:\n",
    "    from google.colab import drive\n",
    "    if not os.path.exists(\"/content/drive\"):\n",
    "        print(\"üîó Connecting to Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "    drive_path = Path(f\"/content/drive/MyDrive/{drive_folder_name}\")\n",
    "    drive_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create subfolders on drive\n",
    "    (drive_path / \"weights\").mkdir(exist_ok=True)\n",
    "    (drive_path / \"logs\").mkdir(exist_ok=True)\n",
    "    (drive_path / \"models\").mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"üìÅ Drive storage set to: {drive_path}\")\n",
    "    \n",
    "    # Symlink local folders to Drive\n",
    "    # This means files saved locally automatically go to Drive\n",
    "    print(\"üîÑ Creating symlinks...\")\n",
    "    \n",
    "    folders_to_sync = [\"weights\", \"logs\", \"models\"]\n",
    "    \n",
    "    for folder in folders_to_sync:\n",
    "        local_target = PROJECT_DIR / folder\n",
    "        drive_target = drive_path / folder\n",
    "        \n",
    "        if local_target.exists() and not local_target.is_symlink():\n",
    "            shutil.rmtree(local_target)\n",
    "        elif local_target.is_symlink():\n",
    "            local_target.unlink()\n",
    "            \n",
    "        local_target.symlink_to(drive_target)\n",
    "        print(f\"  ‚úÖ Linked {folder} <--> Drive\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Drive mounting skipped. Models will be lost when runtime ends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_downloader",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title ## üì• 3. Model Downloader\n",
    "# @markdown Paste a URL (HuggingFace, Pixeldrain, etc.) to download a voice model directly.\n",
    "\n",
    "model_url = \"\" #@param {type:\"string\"}\n",
    "model_name = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# @markdown *Leave `model_name` empty to attempt auto-detection.*\n",
    "\n",
    "import zipfile\n",
    "\n",
    "if model_url:\n",
    "    print(f\"‚¨áÔ∏è Downloading model...\")\n",
    "    \n",
    "    # Handle Pixeldrain/HuggingFace specific quirks\n",
    "    if \"pixeldrain.com\" in model_url:\n",
    "        model_url = f\"https://pixeldrain.com/api/file/{model_url.split('/')[-1]}\"\n",
    "    if \"huggingface.co\" in model_url and \"/blob/\" in model_url:\n",
    "        model_url = model_url.replace(\"/blob/\", \"/resolve/\")\n",
    "\n",
    "    output_name = model_name if model_name else \"temp_model\"\n",
    "    download_path = PROJECT_DIR / \"weights\" / f\"{output_name}.zip\"\n",
    "    \n",
    "    # Use aria2 for speed\n",
    "    subprocess.run(f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -o '{output_name}.zip' -d '{PROJECT_DIR}/weights' '{model_url}'\", shell=True)\n",
    "    \n",
    "    # Check if it's a zip and extract\n",
    "    downloaded_file = PROJECT_DIR / \"weights\" / f\"{output_name}.zip\"\n",
    "    \n",
    "    # If user provided a direct .pth link, aria2 might have named it .zip based on my command above if name wasn't detected\n",
    "    # Let's try to detect the file type\n",
    "    \n",
    "    if downloaded_file.exists():\n",
    "        try:\n",
    "            with zipfile.ZipFile(downloaded_file, 'r') as zip_ref:\n",
    "                print(\"üì¶ Extracting zip file...\")\n",
    "                zip_ref.extractall(PROJECT_DIR / \"weights\")\n",
    "            downloaded_file.unlink() # remove zip after extraction\n",
    "            print(f\"‚úÖ Model extracted to weights folder!\")\n",
    "        except zipfile.BadZipFile:\n",
    "            print(\"üìÑ File is not a zip, assuming raw .pth file.\")\n",
    "            if not model_name:\n",
    "                 # Try to rename based on URL if no name provided\n",
    "                 pass\n",
    "            print(\"‚úÖ Model downloaded!\")\n",
    "    else:\n",
    "        # Sometimes aria2 keeps original filename\n",
    "        print(\"‚úÖ Download complete (Original filename preserved).\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No URL provided. Skipping download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_app",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title ## üöÄ 4. Launch Interface\n",
    "# @markdown Select your preferred method to access the WebUI.\n",
    "\n",
    "tunnel_method = \"gradio\" #@param [\"gradio\", \"ngrok\"]\n",
    "ngrok_token = \"\" #@param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "if tunnel_method == \"ngrok\":\n",
    "    if not ngrok_token:\n",
    "        print(\"‚ùå Error: Ngrok selected but no token provided.\")\n",
    "        print(\"üëâ Sign up at https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    else:\n",
    "        from pyngrok import ngrok, conf\n",
    "        print(\"üîå Authenticating with Ngrok...\")\n",
    "        conf.get_default().auth_token = ngrok_token\n",
    "        conf.get_default().monitor_thread = False\n",
    "        try:\n",
    "            ssh_tunnel = ngrok.connect(7865)\n",
    "            print(f\"üåü Ngrok Tunnel Active: {ssh_tunnel.public_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Ngrok Error: {e}\")\n",
    "\n",
    "print(\"\\nüî• Starting RVC WebUI... Please wait...\")\n",
    "print(\"üìã If using Gradio, look for the 'Running on public URL' link below.\")\n",
    "\n",
    "cmd = \"python app.py --port 7865 --listen\"\n",
    "\n",
    "if tunnel_method == \"gradio\":\n",
    "    cmd += \" --share\"\n",
    "\n",
    "subprocess.run(cmd, shell=True)\n"
   ]
  }
 ]
}
